{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Tutoriel sur la Préparation des données textuelles**\n",
        "**Enseignante:** Asmaa BENGUEDDACH\n",
        "\n",
        "**Niveau:** Master\n",
        "\n",
        "**Durée:** (3 heures)"
      ],
      "metadata": {
        "id": "PvHrUpdGMHKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Partie 1 :Préparation des données textuelles**"
      ],
      "metadata": {
        "id": "JNiQCgFbNN2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pourquoi préparer les données ?**\n",
        "- Les textes bruts contiennent du bruit (ponctuation, majuscules, etc.).\n",
        "- Objectif : Préparer un texte utilisable pour :\n",
        "  - Analyse.\n",
        "  - Machine Learning."
      ],
      "metadata": {
        "id": "CP27zTqUNfHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Concepts clés**\n",
        "1. **Nettoyage :** Retirer ponctuation, espaces inutiles, etc.\n",
        "2. **Tokenisation :** Découper un texte en mots (tokens).\n",
        "3. **Lemmatisation :** Réduire les mots à leur forme de base.\n",
        "4. **Stopwords :** Retirer les mots fréquents mais inutiles (\"et\", \"le\")."
      ],
      "metadata": {
        "id": "tcXMQ0i5OxOO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Nettoyage\n",
        "- Conversion en minuscules.\n",
        "- Suppression de la ponctuation et des caractères inutiles."
      ],
      "metadata": {
        "id": "jfp71Al3Phsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemple de texte\n",
        "text = \"Bonjour! Le ciel est bleu, mais il peut pleuvoir aujourd'hui.\"\n",
        "\n",
        "# 1. Nettoyage\n",
        "# Supprimer la ponctuation et mettre en minuscules\n",
        "text_cleaned = re.sub(r'[^a-zA-Z\\s]', '', text.lower())  # Retirer tout sauf lettres et espaces\n",
        "print(\"Nettoyage :\", text_cleaned)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORrhSjhqNYAn",
        "outputId": "166715d6-cd75-422c-aa90-3cd6e64a75c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nettoyage : bonjour le ciel est bleu mais il peut pleuvoir aujourdhui\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explication:**\n",
        "- On supprime la ponctuation et on convertit le texte en minuscules pour uniformiser les données.\n",
        "- Exemple de transformation : \"Bonjour! Le ciel est bleu...\" devient \"bonjour le ciel est bleu ...\"."
      ],
      "metadata": {
        "id": "LG0mr2Ryr8Xo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Tokenisation\n",
        "Découper le texte en mots."
      ],
      "metadata": {
        "id": "lCT6XaqpR494"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdIDa6d6Luz1",
        "outputId": "44de5a10-ae58-4ebd-8522-af416bb34292"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenisation : ['bonjour', 'le', 'ciel', 'est', 'bleu', 'mais', 'il', 'peut', 'pleuvoir', 'aujourdhui']\n"
          ]
        }
      ],
      "source": [
        "# 2. Tokenisation\n",
        "# Diviser le texte nettoyé en tokens\n",
        "doc = nlp(text_cleaned)\n",
        "tokens = [token.text for token in doc]\n",
        "print(\"Tokenisation :\", tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explication :**\n",
        "- Le texte nettoyé est divisé en mots (tokens). Cela transforme \"bonjour le ciel est bleu\" en une liste de mots : [\"bonjour\", \"le\", \"ciel\", \"est\", \"bleu\"]."
      ],
      "metadata": {
        "id": "a9370wVUsMms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Lemmatisation\n",
        "- But : Réduire un mot à sa forme de base ou à son lemme.\n",
        "- Pourquoi ? Pour normaliser les mots afin qu'ils aient la même forme de base et soient mieux analysés."
      ],
      "metadata": {
        "id": "CDCfgHCzSSEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install spacy\n",
        "#!python -m spacy download fr_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiH638BgS6IM",
        "outputId": "4396c78d-a78d-477f-f41a-acbca2455ea5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting fr-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Lemmatisation\n",
        "# Appliquer la lemmatisation : réduire chaque mot à sa forme de base\n",
        "lemmas = [token.lemma_ for token in doc]\n",
        "print(\"Lemmatisation :\", lemmas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiJhVL3InrUB",
        "outputId": "ee4a7f51-1d89-4023-d499-e5fe9b90eaa2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatisation : ['bonjour', 'le', 'ciel', 'être', 'bleu', 'mais', 'il', 'pouvoir', 'pleuvoir', 'aujourdhui']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explication :**\n",
        "  - `est` devient `être` (forme de base).\n",
        "  - `peut` devient `pouvoir` (forme de base).\n",
        "  - `bleu` reste `bleu` car il n'a pas de variation.\n"
      ],
      "metadata": {
        "id": "wnlnNHYUn2Gg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Stopwords\n",
        "- **But :** Supprimer les mots très fréquents qui n'ajoutent pas de sens pertinent à l'analyse.\n",
        "- **Exemple :**\n",
        "  - \"le\", \"la\", \"et\", \"de\", \"en\" (mots de fonction).\n",
        "- **Pourquoi ?** Ces mots sont très courants, mais n'apportent aucune information utile pour les tâches de traitement de texte (analyse de sentiment, recherche d'information, etc.)."
      ],
      "metadata": {
        "id": "TGAQT4x_Tj_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Suppression des stopwords\n",
        "# Enlever les mots de type stopwords\n",
        "stopwords_removed = [token.lemma_ for token in doc if not token.is_stop]\n",
        "print(\"Stopwords supprimés :\", stopwords_removed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSSBtTRUSkpN",
        "outputId": "72ff0aca-f350-41e5-8a41-110e2cea2176"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopwords supprimés : ['bonjour', 'ciel', 'bleu', 'pleuvoir', 'aujourdhui']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explication**\n",
        "- Les mots fréquents et peu informatifs comme \"le\", \"est\", \"il\" sont supprimés.\n",
        "- Exemple : \"le\" et \"est\" sont enlevés car ce sont des stopwords."
      ],
      "metadata": {
        "id": "BS8sNEEjs6ds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Le code Complet\n",
        "\n",
        "import spacy\n",
        "import re\n",
        "\n",
        "# Charger le modèle spaCy pour la langue française\n",
        "nlp = spacy.load(\"fr_core_news_sm\")\n",
        "\n",
        "# Exemple de texte\n",
        "text = \"Bonjour! Le ciel est bleu, mais il peut pleuvoir aujourd'hui.\"\n",
        "\n",
        "# 1. Nettoyage\n",
        "# Supprimer la ponctuation et mettre en minuscules\n",
        "text_cleaned = re.sub(r'[^a-zA-Z\\s]', '', text.lower())  # Retirer tout sauf lettres et espaces\n",
        "print(\"Nettoyage :\", text_cleaned)\n",
        "\n",
        "# 2. Tokenisation\n",
        "# Diviser le texte nettoyé en tokens\n",
        "doc = nlp(text_cleaned)\n",
        "tokens = [token.text for token in doc]\n",
        "print(\"Tokenisation :\", tokens)\n",
        "\n",
        "# 3. Lemmatisation\n",
        "# Appliquer la lemmatisation : réduire chaque mot à sa forme de base\n",
        "lemmas = [token.lemma_ for token in doc]\n",
        "print(\"Lemmatisation :\", lemmas)\n",
        "\n",
        "# 4. Suppression des stopwords\n",
        "# Enlever les mots de type stopwords\n",
        "stopwords_removed = [token.lemma_ for token in doc if not token.is_stop]\n",
        "print(\"Stopwords supprimés :\", stopwords_removed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hggynGRype9f",
        "outputId": "05842709-8403-4f7b-99fd-70dcb41a19d9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nettoyage : bonjour le ciel est bleu mais il peut pleuvoir aujourdhui\n",
            "Tokenisation : ['bonjour', 'le', 'ciel', 'est', 'bleu', 'mais', 'il', 'peut', 'pleuvoir', 'aujourdhui']\n",
            "Lemmatisation : ['bonjour', 'le', 'ciel', 'être', 'bleu', 'mais', 'il', 'pouvoir', 'pleuvoir', 'aujourdhui']\n",
            "Stopwords supprimés : ['bonjour', 'ciel', 'bleu', 'pleuvoir', 'aujourdhui']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Projet Pratique : Préparation des Données Textuelles (MedQuAD)**"
      ],
      "metadata": {
        "id": "WI4iEH5cz3-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Téléchargement du Dataset MedQuAD**\n",
        "- Le dataset MedQuAD contient des questions-réponses médicales. Vous pouvez télécharger le dataset [ici](https://www.kaggle.com/datasets/pythonafroz/medquad-medical-question-answer-for-ai-research).\n",
        "- Vous pouvez l'utiliser dans votre projet en remplaçant le chemin 'data/med_data.csv' par le chemin réel où vous avez stocké ce fichier."
      ],
      "metadata": {
        "id": "GF2a14KE0jCg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8StPL-c_s_nS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}